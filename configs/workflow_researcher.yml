chatbot1:
    server_model: models/Llama-3.2-3B-Instruct-GGUF/Llama-3.2-3B-Instruct-f16.gguf
    client_model: openai/meta-llama/Llama-3.2-3B-Instruct
    num_requests: 4
    device: gpu
    type: chatbot
    mps: 100

chatbot2:
    server_model: models/Llama-3.2-3B-Instruct-GGUF/Llama-3.2-3B-Instruct-f16.gguf
    client_model: openai/meta-llama/Llama-3.2-3B-Instruct
    num_requests: 3
    device: gpu
    type: chatbot
    mps: 100

deep_research:
    server_model: models/Llama-3.2-3B-Instruct-GGUF/Llama-3.2-3B-Instruct-f16.gguf
    client_model: openai/meta-llama/Llama-3.2-3B-Instruct
    num_requests: 1
    device: gpu
    type: deep_research
    mps: 100

imagegen1:
    server_model: /mnt/tmpfs/models/stable-diffusion-3.5-medium-turbo
    num_requests: 4
    device: gpu
    type: imagegen
    mps: 100

lv:
    num_requests: 1
    device: gpu
    mps: 100
    type: live_captions  

workflows:
    transcript:
        uses: lv
    
    related_research:
        uses: deep_research
        background: true

    refine_meeting:
        uses: chatbot1
        depend_on: ["transcript"]

    generate_image:
        uses: imagegen1
        depend_on: ["refine_meeting"]

    refine_research:
        uses: chatbot2
        depend_on: ["related_research"]