chatbot:
    # server_model = /home/cc/models/Llama-3.2-3B-Instruct-GGUF/Llama-3.2-3B-Instruct-f16.gguf
    server_model = /home/cc/models/Llama-3.1-8B-Instruct-GGUF/Llama-3.1-8B-Instruct-f16.gguf
    # client_model = openai/meta-llama/Llama-3.2-3B-Instruct
    client_model = openai/meta-llama/Llama-3.1-8B-Instruct
    num_requests = 10
    device = gpu
    # device = cpu
    mps = 33

#deep_research:
    #server_model = /home/cc/models/Llama-3.2-3B-Instruct-GGUF/Llama-3.2-3B-Instruct-f16.gguf
    #server_model = /home/cc/models/Llama-3.1-8B-Instruct-GGUF/Llama-3.1-8B-Instruct-f16.gguf
    #client_model = openai/meta-llama/Llama-3.2-3B-Instruct
    #client_model = openai/meta-llama/Llama-3.1-8B-Instruct
    #num_requests = 1
    #device = gpu
    #device = cpu
    #mps = 33

live_captions:
    num_requests = 1
    device = gpu
    # device = cpu
    mps = 33

# imagegen:
    # server_model = /mnt/tmpfs/models/stable-diffusion-3.5-medium-turbo
    # server_model = /home/cc/models/stable-diffusion-3.5-large
    # num_requests = 10
    # device = gpu
    # device = cpu
    # mps = 33