chatbot:
    # server_model = /home/cc/models/Llama-3.2-3B-Instruct-GGUF/Llama-3.2-3B-Instruct-f16.gguf
    server_model = /home/cc/models/Llama-3.1-8B-Instruct-GGUF/Llama-3.1-8B-Instruct-f16.gguf
    # client_model = openai/meta-llama/Llama-3.2-3B-Instruct
    client_model = openai/meta-llama/Llama-3.1-8B-Instruct
    num_requests = 10
    # device = gpu
    device = cpu
    mps = 100

deep_research:
    # server_model = /home/cc/models/Llama-3.2-3B-Instruct-GGUF/Llama-3.2-3B-Instruct-f16.gguf
    server_model = /home/cc/models/Llama-3.1-8B-Instruct-GGUF/Llama-3.1-8B-Instruct-f16.gguf
    # client_model = openai/meta-llama/Llama-3.2-3B-Instruct
    client_model = openai/meta-llama/Llama-3.1-8B-Instruct
    num_requests = 1
    # device = gpu
    device = cpu
    mps = 100

live_captions:
    num_requests = 5
    device = gpu
    # device = cpu
    mps = 50

imagegen:
    # server_model = /mnt/tmpfs/models/stable-diffusion-3.5-medium-turbo
    server_model = /home/cc/models/stable-diffusion-3.5-large
    num_requests = 10
    device = gpu
    # device = cpu
    mps = 50